ğŸ§  AI Career Intelligence & Resumeâ€“JD Matching Assistant

An AI-powered system that analyzes a candidateâ€™s resume against a job description using Retrieval-Augmented Generation (RAG), deterministic skill matching, and LLM-based explanations.

This project is designed as a real-world AI product, focusing on accuracy, explainability, cost control, and user experience.

ğŸš€ Features

ğŸ“„ Resume & Job Description input via file upload OR text paste

ğŸ” Session-aware multi-user architecture (Redis-backed)

ğŸ§  RAG pipeline using FAISS vector store

ğŸ“Š Deterministic Skill Match Percentage

ğŸ’¬ Context-aware AI Chat over Resume & JD

ğŸ“‰ Skill Gap analysis (matched vs missing skills)

âœï¸ Resume rewriting aligned to job requirements

ğŸ¤ Interview question generation

ğŸ“Š ATS keyword extraction

ğŸ¯ Non-technical, guided UI flow (error-proof)

ğŸ› ï¸ Tech Stack
Backend

FastAPI â€“ REST APIs

Redis â€“ Session & document storage

FAISS â€“ Vector similarity search

OpenAI LLM â€“ Mock / Real toggle

Python, Pydantic

Frontend

Streamlit â€“ Interactive UI & chat experience

ğŸ§  Core Design Principles
1ï¸âƒ£ Deterministic over Hallucinated Logic

Skill match percentage is rule-based

LLM is not used for calculations

Formula used:

Skill Match % = (Matched Skills / JD Skills) Ã— 100

2ï¸âƒ£ Explicit RAG Lifecycle

Resume & JD uploaded once per session

Vector store built explicitly by user

No hidden background embedding jobs

Predictable latency & cost control

3ï¸âƒ£ LLM Used Only Where It Makes Sense

LLMs are used for:

Natural language explanations

Resume rewriting

Interview question generation

Conversational AI chat

LLMs are not used for:

Skill matching logic

Percent calculations

Critical decision metrics

ğŸ§© System Architecture
Streamlit UI
   â”‚
   â”‚  REST API (X-Session-ID)
   â–¼
FastAPI Backend
   â”‚
   â”œâ”€â”€ Redis (Resume, JD, Session)
   â”‚
   â”œâ”€â”€ FAISS Vector Store
   â”‚
   â”œâ”€â”€ Skill Extraction & Matching Logic
   â”‚
   â””â”€â”€ LLM (Mock / Real)

ğŸ” Example Workflow

User uploads or pastes Resume & JD

User clicks Prepare AI Analysis

Backend:

Extracts & cleans text

Builds vector store

User explores:

Skill Gap

AI Chat

Resume Rewrite

Interview Questions

ATS Keywords

ğŸ’¬ RAG Chat

Context-aware chat using vector store

Stable chat input (ChatGPT-style UX)

Clear chat support

Session-isolated conversations

ğŸ§ª Mock vs Real LLM
Mode	Purpose
Mock	Development, testing, zero cost
Real	Production & demos

Controlled via environment configuration.

â–¶ï¸ How to Run Locally
1ï¸âƒ£ Start Redis
redis-server

2ï¸âƒ£ Start Backend
uvicorn backend.main:app --reload

3ï¸âƒ£ Start Frontend
streamlit run frontend/app.py

ğŸ“‚ Repository Structure
carrier_ai_assistant/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ main.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ api_client.py
â”‚   â”œâ”€â”€ session.py
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore

ğŸ”’ Security & Privacy

.env excluded via .gitignore

Uploaded resumes & JDs not committed

Redis session data not persisted to GitHub

No secrets in repository

ğŸ¯ Interview-Ready Explanation

â€œThis project combines deterministic skill matching with session-aware RAG. We use LLMs only for language understanding and explanation, ensuring accuracy, transparency, and cost control.â€

ğŸš€ Future Enhancements

Skill weighting (core vs optional)

LLM-based skill normalization

Source citations in RAG responses

Downloadable PDF report

Dockerized deployment

Authentication & user accounts

ğŸ Final Note

This project is built as a production-style AI system, not a demo:

Clear separation of concerns

Explainable AI decisions

Scalable architecture

Non-technical friendly UX
